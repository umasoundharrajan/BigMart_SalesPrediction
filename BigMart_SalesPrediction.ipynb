{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e403bf-70b3-4648-a59e-e76b68754fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37dfc59a-6037-4dab-b1c8-a6623ed4aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a69ad5e-925b-4854-926f-87812cb37aa1",
   "metadata": {},
   "source": [
    "### 1) Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed74c7f-ab69-4af7-9822-0b581b995c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data ####\n",
    "train = pd.read_csv(\"C:/Users/hp/Documents/Analytics_Vidhya/BigMart_SalesPrediction/train_v9rqX0R.csv\")\n",
    "test = pd.read_csv(\"C:/Users/hp/Documents/Analytics_Vidhya/BigMart_SalesPrediction/test_AbJTz2l.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c870c07-d8ad-4f12-b3eb-ad3448c73b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keep raw ids for submission later\n",
    "id_cols = [\"Item_Identifier\", \"Outlet_Identifier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c89460-68e5-40d7-acdf-d413f02fc15d",
   "metadata": {},
   "source": [
    "### 2) Combine & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f846727-7c80-45a6-995e-01ecb8896bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Source\"] = \"train\"\n",
    "test[\"Source\"] = \"test\"\n",
    "test[\"Item_Outlet_Sales\"] = np.nan\n",
    "\n",
    "df = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13aa65df-2e84-4987-9e82-c9c8d694f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalize Item_Fat_Content ---\n",
    "df[\"Item_Fat_Content\"] = df[\"Item_Fat_Content\"].replace({\n",
    "    \"LF\": \"Low Fat\",\n",
    "    \"low fat\": \"Low Fat\",\n",
    "    \"reg\": \"Regular\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdde9fe1-4961-41e1-b328-e454f7295936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item category from ID (FD=Food, DR=Drinks, NC=Non-Consumable)\n",
    "df[\"Item_Category\"] = df[\"Item_Identifier\"].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "230e8996-1998-4336-a742-b46a8f4fbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Consumables should not carry fat tag\n",
    "non_edible_mask = df[\"Item_Category\"] == \"NC\"\n",
    "df.loc[non_edible_mask, \"Item_Fat_Content\"] = \"Non-Edible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d9fd5e0-ca52-4393-abd5-24a3a9bef8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Impute Item_Weight using hierarchical medians ---\n",
    "# 1) by Item_Identifier, 2) by Item_Type, 3) global median\n",
    "w_by_item = df.groupby(\"Item_Identifier\")[\"Item_Weight\"].median()\n",
    "df[\"Item_Weight\"] = df[\"Item_Weight\"].fillna(df[\"Item_Identifier\"].map(w_by_item))\n",
    "w_by_type = df.groupby(\"Item_Type\")[\"Item_Weight\"].transform(\"median\")\n",
    "df[\"Item_Weight\"] = df[\"Item_Weight\"].fillna(w_by_type)\n",
    "df[\"Item_Weight\"] = df[\"Item_Weight\"].fillna(df[\"Item_Weight\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56bf9b90-5d1b-4244-b75f-58e7ca85782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fix Item_Visibility zeros & NAs ---\n",
    "# Replace zeros with item-wise mean (excluding zeros), fallback to global mean\n",
    "vis_nonzero = df.loc[df[\"Item_Visibility\"] > 0, \"Item_Visibility\"]\n",
    "vis_global_mean = vis_nonzero.mean()\n",
    "vis_by_item = (df.assign(iv=lambda x: x[\"Item_Visibility\"].where(x[\"Item_Visibility\"] > 0, np.nan))\n",
    "                 .groupby(\"Item_Identifier\")[\"iv\"].mean())\n",
    "df[\"Item_Visibility\"] = df.apply(\n",
    "    lambda r: vis_by_item.get(r[\"Item_Identifier\"], np.nan)\n",
    "              if r[\"Item_Visibility\"] == 0 else r[\"Item_Visibility\"], axis=1)\n",
    "df[\"Item_Visibility\"] = df[\"Item_Visibility\"].fillna(vis_global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea7de1d6-4b0f-404e-8e2b-73a920d41600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Impute Outlet_Size via Outlet_Type mode ---\n",
    "size_mode_by_type = (df.groupby(\"Outlet_Type\")[\"Outlet_Size\"]\n",
    "                      .agg(lambda s: s.mode().iat[0] if not s.mode().empty else np.nan))\n",
    "df[\"Outlet_Size\"] = df[\"Outlet_Size\"].fillna(df[\"Outlet_Type\"].map(size_mode_by_type))\n",
    "# fallback to global mode\n",
    "if df[\"Outlet_Size\"].isna().any():\n",
    "    global_mode = df[\"Outlet_Size\"].mode()\n",
    "    if not global_mode.empty:\n",
    "        df[\"Outlet_Size\"] = df[\"Outlet_Size\"].fillna(global_mode.iat[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5a839-8107-4c7a-97db-851afc209a7f",
   "metadata": {},
   "source": [
    "#### 3) Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7441565-0355-4f12-b9ea-c22d24b4f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year reference is 2013 per competition statement\n",
    "df[\"Outlet_Age\"] = 2013 - df[\"Outlet_Establishment_Year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bf6b450-9785-4cc2-999d-9be6627357af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility features\n",
    "df[\"Visibility_Mean_Item\"] = df.groupby(\"Item_Identifier\")[\"Item_Visibility\"].transform(\"mean\")\n",
    "df[\"Visibility_Ratio\"] = df[\"Item_Visibility\"] / (df[\"Visibility_Mean_Item\"] + 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e1522f-8cc5-4cf0-9f71-f7dd87a5aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price transforms and bins (non-linear effects)\n",
    "df[\"Item_MRP_log\"] = np.log1p(df[\"Item_MRP\"])\n",
    "df[\"Item_Visibility_log\"] = np.log1p(df[\"Item_Visibility\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b39ac13-6166-4ba6-983b-bb1756a13b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartile bins (labels as integers 0..k-1)\n",
    "df[\"MRP_Bin\"] = pd.qcut(df[\"Item_MRP\"], q=4, labels=False, duplicates=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6f4a67d-a782-4131-91d9-b99eb2137e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encodings (compact signal without exploding dims)\n",
    "df[\"Item_ID_Count\"] = df.groupby(\"Item_Identifier\")[\"Item_Identifier\"].transform(\"count\")\n",
    "df[\"Outlet_ID_Count\"] = df.groupby(\"Outlet_Identifier\")[\"Outlet_Identifier\"].transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cda9011-c3fd-474f-9931-8413b7dd4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional polynomial feature for MRP\n",
    "df[\"Item_MRP_sq\"] = df[\"Item_MRP\"] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd47edb-77f8-4f33-b9cd-85d2c7f4da01",
   "metadata": {},
   "source": [
    "### 4) Encode categoricals (one-hot on full combined data to keep aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40f32e23-635e-43bc-ab5e-68cf1c9c60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    \"Item_Fat_Content\", \"Item_Type\", \"Outlet_Identifier\", \"Outlet_Size\",\n",
    "    \"Outlet_Location_Type\", \"Outlet_Type\", \"Item_Category\", \"MRP_Bin\"\n",
    "]\n",
    "num_cols = [\n",
    "    \"Item_Weight\", \"Item_Visibility\", \"Item_MRP\", \"Outlet_Age\",\n",
    "    \"Visibility_Mean_Item\", \"Visibility_Ratio\", \"Item_MRP_log\",\n",
    "    \"Item_Visibility_log\", \"Item_ID_Count\", \"Outlet_ID_Count\", \"Item_MRP_sq\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2d9717a-8e55-4afd-a671-eb2bcc892ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure MRP_Bin is treated as categorical\n",
    "df[\"MRP_Bin\"] = df[\"MRP_Bin\"].astype(\"category\")\n",
    "\n",
    "# Drop columns that should not be used directly\n",
    "drop_cols = [\"Item_Outlet_Sales\", \"Outlet_Establishment_Year\", \"Source\", \"Item_Identifier\"]\n",
    "\n",
    "X_full = pd.get_dummies(df[cat_cols + num_cols], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "887212f5-b45d-4e2d-8a1a-4e99cefe7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split back\n",
    "mask_train = df[\"Source\"] == \"train\"\n",
    "X = X_full.loc[mask_train].copy()\n",
    "y_raw = train[\"Item_Outlet_Sales\"].values.astype(float)\n",
    "X_test = X_full.loc[~mask_train].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5979c6e9-9ad8-4138-8ed4-79e35411702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target: log-transform for stability\n",
    "y = np.log1p(y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a8a52-d60f-47c1-a9a0-458a4b54d999",
   "metadata": {},
   "source": [
    "### 5) KFold CV + Models (LGB + XGB, fallback to HistGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4cd94c6-5eb8-487b-aee5-8cdfe80931c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 1216.1019\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGB = True\n",
    "except Exception:\n",
    "    HAS_LGB = False\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "oof_pred_linear = np.zeros(len(X))  # store predictions on original sales scale\n",
    "test_pred_linear_accum = np.zeros(len(X_test))\n",
    "\n",
    "# store per-model preds for blending\n",
    "oof_parts = []\n",
    "test_parts = []\n",
    "\n",
    "fold_idx = 1\n",
    "for tr_idx, va_idx in kf.split(X):\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "    fold_preds_linear = []\n",
    "    fold_test_preds_linear = []\n",
    "\n",
    "    # --- LightGBM ---\n",
    "    if HAS_LGB:\n",
    "        lgb_train = lgb.Dataset(X_tr, label=y_tr)\n",
    "        lgb_valid = lgb.Dataset(X_va, label=y_va)\n",
    "        lgb_params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"learning_rate\": 0.035,\n",
    "            \"num_leaves\": 31,\n",
    "            \"feature_fraction\": 0.85,\n",
    "            \"bagging_fraction\": 0.85,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"min_data_in_leaf\": 20,\n",
    "            \"lambda_l1\": 0.0,\n",
    "            \"lambda_l2\": 1.0,\n",
    "            \"verbosity\": -1,\n",
    "            \"seed\": RANDOM_STATE\n",
    "        }\n",
    "        lgb_model = lgb.train(\n",
    "            lgb_params, lgb_train,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[lgb_valid],\n",
    "            early_stopping_rounds=200,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        va_pred_log = lgb_model.predict(X_va, num_iteration=lgb_model.best_iteration)\n",
    "        te_pred_log = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\n",
    "        fold_preds_linear.append(np.expm1(va_pred_log))\n",
    "        fold_test_preds_linear.append(np.expm1(te_pred_log))\n",
    "\n",
    "    # --- XGBoost ---\n",
    "    if HAS_XGB:\n",
    "        xgb_model = xgb.XGBRegressor(\n",
    "            n_estimators=5000,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=7,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            reg_alpha=0.0,\n",
    "            reg_lambda=1.0,\n",
    "            min_child_weight=1.0,\n",
    "            gamma=0.0,\n",
    "            tree_method=\"hist\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "        xgb_model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric=\"rmse\",\n",
    "            verbose=False,\n",
    "            early_stopping_rounds=200,\n",
    "        )\n",
    "        va_pred_log = xgb_model.predict(X_va)\n",
    "        te_pred_log = xgb_model.predict(X_test)\n",
    "        fold_preds_linear.append(np.expm1(va_pred_log))\n",
    "        fold_test_preds_linear.append(np.expm1(te_pred_log))\n",
    "\n",
    "    # --- Fallback: HistGradientBoosting (sklearn) ---\n",
    "    if not HAS_LGB and not HAS_XGB:\n",
    "        hgb = HistGradientBoostingRegressor(\n",
    "            max_depth=None,\n",
    "            learning_rate=0.06,\n",
    "            max_iter=1200,\n",
    "            min_samples_leaf=20,\n",
    "            l2_regularization=0.0,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        hgb.fit(X_tr, y_tr)\n",
    "        va_pred_log = hgb.predict(X_va)\n",
    "        te_pred_log = hgb.predict(X_test)\n",
    "        fold_preds_linear.append(np.expm1(va_pred_log))\n",
    "        fold_test_preds_linear.append(np.expm1(te_pred_log))\n",
    "\n",
    "    # Blend within-fold (weighted average). Prefer LGB over XGB slightly if both exist\n",
    "    if len(fold_preds_linear) == 2:\n",
    "        va_blend = 0.6 * fold_preds_linear[0] + 0.4 * fold_preds_linear[1]\n",
    "        te_blend = 0.6 * fold_test_preds_linear[0] + 0.4 * fold_test_preds_linear[1]\n",
    "    else:\n",
    "        va_blend = fold_preds_linear[0]\n",
    "        te_blend = fold_test_preds_linear[0]\n",
    "\n",
    "    oof_pred_linear[va_idx] = va_blend\n",
    "    test_pred_linear_accum += te_blend\n",
    "    oof_parts.append(va_blend)\n",
    "    test_parts.append(te_blend)\n",
    "\n",
    "    fold_idx += 1\n",
    "\n",
    "# Average test predictions over folds\n",
    "test_pred_linear = test_pred_linear_accum / kf.get_n_splits()\n",
    "\n",
    "# Evaluate CV RMSE on original scale\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_raw, y_pred=oof_pred_linear))\n",
    "print(f\"CV RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600355e4-b08a-4378-a6ee-3b5476f65bd5",
   "metadata": {},
   "source": [
    "#### 6) Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5e892fe-8b7c-4110-a5f1-56b8f001d811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: bigmart_submission.csv\n",
      "OOF predictions saved to: oof_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# sub = df.loc[~mask_train, id_cols].copy()\n",
    "# sub[\"Item_Outlet_Sales\"] = test_pred_linear\n",
    "# sub.to_csv(\"bigmart_submission.csv\", index=False)\n",
    "# print(\"Submission saved to: bigmart_submission.csv\")\n",
    "\n",
    "# pd.DataFrame({\"Item_Outlet_Sales_OOF\": oof_pred_linear}).to_csv(\"oof_predictions.csv\", index=False)\n",
    "# print(\"OOF predictions saved to: oof_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73db59dd-0714-43d4-aa7f-4f85ab3258af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: bigmart_submission_20250817_163008.csv\n",
      "OOF predictions saved to: oof_predictions_20250817_163008.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# After predictions are generated:\n",
    "id_cols = [\"Item_Identifier\", \"Outlet_Identifier\"]\n",
    "sub = df.loc[~mask_train, id_cols].copy()\n",
    "sub[\"Item_Outlet_Sales\"] = test_pred_linear\n",
    "\n",
    "# Generate timestamp string\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save submission in current working directory\n",
    "sub_filename = f\"bigmart_submission_{timestamp}.csv\"\n",
    "sub.to_csv(sub_filename, index=False)\n",
    "print(f\"Submission saved to: {sub_filename}\")\n",
    "\n",
    "# Also save OOF predictions (optional)\n",
    "oof_filename = f\"oof_predictions_{timestamp}.csv\"\n",
    "pd.DataFrame({\"Item_Outlet_Sales_OOF\": oof_pred_linear}).to_csv(oof_filename, index=False)\n",
    "print(f\"OOF predictions saved to: {oof_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
